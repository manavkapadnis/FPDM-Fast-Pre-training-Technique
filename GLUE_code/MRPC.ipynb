{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install fasthugs","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2022-06-01T20:30:10.370116Z","iopub.execute_input":"2022-06-01T20:30:10.370571Z","iopub.status.idle":"2022-06-01T20:30:35.365953Z","shell.execute_reply.started":"2022-06-01T20:30:10.370532Z","shell.execute_reply":"2022-06-01T20:30:35.364706Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting fasthugs\n  Downloading fasthugs-0.0.1-py3-none-any.whl (15 kB)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from fasthugs) (21.3)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (from fasthugs) (4.18.0)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.7/site-packages (from fasthugs) (2.1.0)\nRequirement already satisfied: fastcore in /opt/conda/lib/python3.7/site-packages (from fasthugs) (1.4.3)\nRequirement already satisfied: torch>=1.7.1 in /opt/conda/lib/python3.7/site-packages (from fasthugs) (1.11.0)\nRequirement already satisfied: pip in /opt/conda/lib/python3.7/site-packages (from fasthugs) (22.1)\nRequirement already satisfied: fastai>=2.2.2 in /opt/conda/lib/python3.7/site-packages (from fasthugs) (2.6.3)\nRequirement already satisfied: torchvision>=0.8.2 in /opt/conda/lib/python3.7/site-packages (from fastai>=2.2.2->fasthugs) (0.12.0)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from fastai>=2.2.2->fasthugs) (1.3.5)\nRequirement already satisfied: fastprogress>=0.2.4 in /opt/conda/lib/python3.7/site-packages (from fastai>=2.2.2->fasthugs) (1.0.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from fastai>=2.2.2->fasthugs) (1.7.3)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from fastai>=2.2.2->fasthugs) (3.5.2)\nRequirement already satisfied: pillow>6.0.0 in /opt/conda/lib/python3.7/site-packages (from fastai>=2.2.2->fasthugs) (9.1.0)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from fastai>=2.2.2->fasthugs) (6.0)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from fastai>=2.2.2->fasthugs) (1.0.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from fastai>=2.2.2->fasthugs) (2.27.1)\nRequirement already satisfied: fastdownload<2,>=0.0.5 in /opt/conda/lib/python3.7/site-packages (from fastai>=2.2.2->fasthugs) (0.0.6)\nRequirement already satisfied: spacy<4 in /opt/conda/lib/python3.7/site-packages (from fastai>=2.2.2->fasthugs) (3.2.4)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.7.1->fasthugs) (4.2.0)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.7/site-packages (from datasets->fasthugs) (3.0.0)\nRequirement already satisfied: dill in /opt/conda/lib/python3.7/site-packages (from datasets->fasthugs) (0.3.5.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from datasets->fasthugs) (1.21.6)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from datasets->fasthugs) (3.8.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.7/site-packages (from datasets->fasthugs) (0.70.13)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.7/site-packages (from datasets->fasthugs) (2022.5.0)\nRequirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from datasets->fasthugs) (0.5.1)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from datasets->fasthugs) (4.11.4)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.7/site-packages (from datasets->fasthugs) (4.64.0)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.7/site-packages (from datasets->fasthugs) (5.0.0)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.7/site-packages (from datasets->fasthugs) (0.18.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->fasthugs) (3.0.9)\nRequirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers->fasthugs) (0.0.53)\nRequirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers->fasthugs) (0.12.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers->fasthugs) (2021.11.10)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers->fasthugs) (3.6.0)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->fastai>=2.2.2->fasthugs) (2022.5.18.1)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests->fastai>=2.2.2->fasthugs) (2.0.12)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->fastai>=2.2.2->fasthugs) (1.26.9)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->fastai>=2.2.2->fasthugs) (3.3)\nCollecting typing-extensions\n  Downloading typing_extensions-3.10.0.2-py3-none-any.whl (26 kB)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai>=2.2.2->fasthugs) (3.3.0)\nRequirement already satisfied: thinc<8.1.0,>=8.0.12 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai>=2.2.2->fasthugs) (8.0.16)\nRequirement already satisfied: blis<0.8.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai>=2.2.2->fasthugs) (0.7.7)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai>=2.2.2->fasthugs) (3.0.9)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai>=2.2.2->fasthugs) (3.1.2)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai>=2.2.2->fasthugs) (1.0.2)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai>=2.2.2->fasthugs) (1.0.7)\nRequirement already satisfied: srsly<3.0.0,>=2.4.1 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai>=2.2.2->fasthugs) (2.4.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai>=2.2.2->fasthugs) (59.8.0)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai>=2.2.2->fasthugs) (1.8.2)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai>=2.2.2->fasthugs) (2.0.7)\nRequirement already satisfied: typer<0.5.0,>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai>=2.2.2->fasthugs) (0.4.1)\nRequirement already satisfied: wasabi<1.1.0,>=0.8.1 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai>=2.2.2->fasthugs) (0.9.1)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai>=2.2.2->fasthugs) (3.0.6)\nRequirement already satisfied: click<8.1.0 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai>=2.2.2->fasthugs) (8.0.4)\nRequirement already satisfied: pathy>=0.3.5 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai>=2.2.2->fasthugs) (0.6.1)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai>=2.2.2->fasthugs) (2.0.6)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets->fasthugs) (4.0.2)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets->fasthugs) (6.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets->fasthugs) (1.7.2)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets->fasthugs) (21.4.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets->fasthugs) (1.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets->fasthugs) (1.3.0)\nRequirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets->fasthugs) (0.13.0)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->datasets->fasthugs) (3.8.0)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib->fastai>=2.2.2->fasthugs) (2.8.2)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->fastai>=2.2.2->fasthugs) (4.33.3)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->fastai>=2.2.2->fasthugs) (1.4.2)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->fastai>=2.2.2->fasthugs) (0.11.0)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->fastai>=2.2.2->fasthugs) (2022.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers->fasthugs) (1.16.0)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers->fasthugs) (1.1.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->fastai>=2.2.2->fasthugs) (3.1.0)\nRequirement already satisfied: smart-open<6.0.0,>=5.0.0 in /opt/conda/lib/python3.7/site-packages (from pathy>=0.3.5->spacy<4->fastai>=2.2.2->fasthugs) (5.2.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.7/site-packages (from jinja2->spacy<4->fastai>=2.2.2->fasthugs) (2.0.1)\nInstalling collected packages: typing-extensions, fasthugs\n  Attempting uninstall: typing-extensions\n    Found existing installation: typing_extensions 4.2.0\n    Uninstalling typing_extensions-4.2.0:\n      Successfully uninstalled typing_extensions-4.2.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-io 0.21.0 requires tensorflow-io-gcs-filesystem==0.21.0, which is not installed.\ntensorflow 2.6.4 requires absl-py~=0.10, but you have absl-py 1.0.0 which is incompatible.\ntensorflow 2.6.4 requires numpy~=1.19.2, but you have numpy 1.21.6 which is incompatible.\ntensorflow 2.6.4 requires six~=1.15.0, but you have six 1.16.0 which is incompatible.\ntensorflow 2.6.4 requires wrapt~=1.12.1, but you have wrapt 1.14.1 which is incompatible.\ntensorflow-transform 1.8.0 requires tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<2.9,>=1.15.5, but you have tensorflow 2.6.4 which is incompatible.\ntensorflow-serving-api 2.8.0 requires tensorflow<3,>=2.8.0, but you have tensorflow 2.6.4 which is incompatible.\nrich 12.4.4 requires typing-extensions<5.0,>=4.0.0; python_version < \"3.9\", but you have typing-extensions 3.10.0.2 which is incompatible.\npytorch-lightning 1.6.3 requires typing-extensions>=4.0.0, but you have typing-extensions 3.10.0.2 which is incompatible.\npytools 2022.1.9 requires typing-extensions>=4.0; python_version < \"3.11\", but you have typing-extensions 3.10.0.2 which is incompatible.\nflax 0.5.0 requires typing-extensions>=4.1.1, but you have typing-extensions 3.10.0.2 which is incompatible.\nflake8 4.0.1 requires importlib-metadata<4.3; python_version < \"3.8\", but you have importlib-metadata 4.11.4 which is incompatible.\napache-beam 2.38.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.5.1 which is incompatible.\napache-beam 2.38.0 requires httplib2<0.20.0,>=0.8, but you have httplib2 0.20.4 which is incompatible.\naioitertools 0.10.0 requires typing_extensions>=4.0; python_version < \"3.10\", but you have typing-extensions 3.10.0.2 which is incompatible.\naiobotocore 2.3.2 requires botocore<1.24.22,>=1.24.21, but you have botocore 1.26.7 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed fasthugs-0.0.1 typing-extensions-3.10.0.2\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification\nfrom fastai.text.all import *\nfrom fastai.callback.wandb import *\n\nfrom fasthugs.learner import TransLearner\nfrom fasthugs.data import TransformersTextBlock, TextGetter, get_splits, PreprocCategoryBlock\n\nfrom datasets import load_dataset, concatenate_datasets\n\nimport random \nimport numpy as np\nimport torch\n\ndef random_seed(seed_value): \n    np.random.seed(seed_value) \n    torch.manual_seed(seed_value)\n    random.seed(seed_value) \n\n\nrandom_seed(42)","metadata":{"execution":{"iopub.status.busy":"2022-06-01T20:30:35.371125Z","iopub.execute_input":"2022-06-01T20:30:35.373510Z","iopub.status.idle":"2022-06-01T20:30:36.227776Z","shell.execute_reply.started":"2022-06-01T20:30:35.373467Z","shell.execute_reply":"2022-06-01T20:30:36.226972Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"ds_name = 'glue'\nmodel_name = \"AnonymousSub/rule_based_roberta_hier_triplet_epochs_1_shard_1\"\n\nmax_len = 512\nbs = 32\nval_bs = bs*2\n\nlr = 3e-5","metadata":{"execution":{"iopub.status.busy":"2022-06-01T20:30:36.232206Z","iopub.execute_input":"2022-06-01T20:30:36.234824Z","iopub.status.idle":"2022-06-01T20:30:36.241358Z","shell.execute_reply.started":"2022-06-01T20:30:36.234784Z","shell.execute_reply":"2022-06-01T20:30:36.240575Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"GLUE_TASKS = [\"cola\", \"mnli\", \"mnli-mm\", \"mrpc\", \"qnli\", \"qqp\", \"rte\", \"sst2\", \"stsb\", \"wnli\"]\ndef validate_task():\n    assert task in GLUE_TASKS","metadata":{"execution":{"iopub.status.busy":"2022-06-01T20:30:36.247545Z","iopub.execute_input":"2022-06-01T20:30:36.249816Z","iopub.status.idle":"2022-06-01T20:30:36.256384Z","shell.execute_reply.started":"2022-06-01T20:30:36.249754Z","shell.execute_reply":"2022-06-01T20:30:36.255374Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"from fastai.metrics import MatthewsCorrCoef, F1Score, PearsonCorrCoef, SpearmanCorrCoef","metadata":{"execution":{"iopub.status.busy":"2022-06-01T20:30:36.261621Z","iopub.execute_input":"2022-06-01T20:30:36.264011Z","iopub.status.idle":"2022-06-01T20:30:36.270336Z","shell.execute_reply.started":"2022-06-01T20:30:36.263969Z","shell.execute_reply":"2022-06-01T20:30:36.269395Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"glue_metrics = {\n    'cola':[MatthewsCorrCoef()],\n    'sst2':[accuracy],\n    'mrpc':[F1Score(), accuracy],\n    'stsb':[PearsonCorrCoef(), SpearmanCorrCoef()],\n    'qqp' :[F1Score(), accuracy],\n    'mnli':[accuracy],\n    'qnli':[accuracy],\n    'rte' :[accuracy],\n    'wnli':[accuracy],\n}","metadata":{"execution":{"iopub.status.busy":"2022-06-01T20:30:36.275269Z","iopub.execute_input":"2022-06-01T20:30:36.278144Z","iopub.status.idle":"2022-06-01T20:30:36.286078Z","shell.execute_reply.started":"2022-06-01T20:30:36.278107Z","shell.execute_reply":"2022-06-01T20:30:36.285241Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"task = 'mrpc'\nvalidate_task()","metadata":{"execution":{"iopub.status.busy":"2022-06-01T20:30:36.291148Z","iopub.execute_input":"2022-06-01T20:30:36.293515Z","iopub.status.idle":"2022-06-01T20:30:36.299352Z","shell.execute_reply.started":"2022-06-01T20:30:36.293479Z","shell.execute_reply":"2022-06-01T20:30:36.298518Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"ds = load_dataset(ds_name, task)","metadata":{"execution":{"iopub.status.busy":"2022-06-01T20:30:36.301615Z","iopub.execute_input":"2022-06-01T20:30:36.302636Z","iopub.status.idle":"2022-06-01T20:30:46.109490Z","shell.execute_reply.started":"2022-06-01T20:30:36.302599Z","shell.execute_reply":"2022-06-01T20:30:46.108750Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/7.78k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f41c43aae594478087490b017986e1b9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading metadata:   0%|          | 0.00/4.47k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e33e1f943efa422590529460e34e3531"}},"metadata":{}},{"name":"stdout","text":"Downloading and preparing dataset glue/mrpc (download: 1.43 MiB, generated: 1.43 MiB, post-processed: Unknown size, total: 2.85 MiB) to /root/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd089c36529242f08c2f1ba72f8de3ef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb68c17e315a4512aaabf535e19d6fe2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"789473502dd1450c88b99e7945558140"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"995a004bd20345a2ba2595072a37cb93"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/3668 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/408 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/1725 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset glue downloaded and prepared to /root/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6465d718df9340f3847120574ca4f59c"}},"metadata":{}}]},{"cell_type":"code","source":"ds.keys()","metadata":{"execution":{"iopub.status.busy":"2022-06-01T20:30:46.111613Z","iopub.execute_input":"2022-06-01T20:30:46.114506Z","iopub.status.idle":"2022-06-01T20:30:46.127215Z","shell.execute_reply.started":"2022-06-01T20:30:46.114466Z","shell.execute_reply":"2022-06-01T20:30:46.126397Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"dict_keys(['train', 'validation', 'test'])"},"metadata":{}}]},{"cell_type":"code","source":"len(ds['train']), len(ds['validation'])","metadata":{"execution":{"iopub.status.busy":"2022-06-01T20:30:46.132586Z","iopub.execute_input":"2022-06-01T20:30:46.135208Z","iopub.status.idle":"2022-06-01T20:30:46.154203Z","shell.execute_reply.started":"2022-06-01T20:30:46.135170Z","shell.execute_reply":"2022-06-01T20:30:46.153226Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"(3668, 408)"},"metadata":{}}]},{"cell_type":"code","source":"train_idx, valid_idx = get_splits(ds)\nvalid_idx","metadata":{"execution":{"iopub.status.busy":"2022-06-01T20:30:46.158590Z","iopub.execute_input":"2022-06-01T20:30:46.160641Z","iopub.status.idle":"2022-06-01T20:30:46.169465Z","shell.execute_reply.started":"2022-06-01T20:30:46.160605Z","shell.execute_reply":"2022-06-01T20:30:46.168600Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"(#408) [3668,3669,3670,3671,3672,3673,3674,3675,3676,3677...]"},"metadata":{}}]},{"cell_type":"code","source":"train_ds = concatenate_datasets([ds['train'], ds['validation']])","metadata":{"execution":{"iopub.status.busy":"2022-06-01T20:30:46.172530Z","iopub.execute_input":"2022-06-01T20:30:46.173995Z","iopub.status.idle":"2022-06-01T20:30:46.184359Z","shell.execute_reply.started":"2022-06-01T20:30:46.173958Z","shell.execute_reply":"2022-06-01T20:30:46.183642Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"train_ds[0]","metadata":{"execution":{"iopub.status.busy":"2022-06-01T20:30:46.188287Z","iopub.execute_input":"2022-06-01T20:30:46.188841Z","iopub.status.idle":"2022-06-01T20:30:46.199040Z","shell.execute_reply.started":"2022-06-01T20:30:46.188805Z","shell.execute_reply":"2022-06-01T20:30:46.198157Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"{'sentence1': 'Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence .',\n 'sentence2': 'Referring to him as only \" the witness \" , Amrozi accused his brother of deliberately distorting his evidence .',\n 'label': 1,\n 'idx': 0}"},"metadata":{}}]},{"cell_type":"code","source":"vocab = train_ds.features['label'].names\ndblock = DataBlock(blocks = [TransformersTextBlock(pretrained_model_name=model_name), PreprocCategoryBlock(vocab)],\n                   get_x=TextGetter('sentence1', 'sentence2'),\n                   get_y=ItemGetter('label'),\n                   splitter=IndexSplitter(valid_idx))","metadata":{"execution":{"iopub.status.busy":"2022-06-01T20:30:46.201417Z","iopub.execute_input":"2022-06-01T20:30:46.206428Z","iopub.status.idle":"2022-06-01T20:30:54.012609Z","shell.execute_reply.started":"2022-06-01T20:30:46.206390Z","shell.execute_reply":"2022-06-01T20:30:54.011801Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/384 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"55888993d306478bb918ff4f42f30d51"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/780k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e4109d9d58884a2895c37724d66896c2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6272e215656e4ffe9f2b2dd3fa31f996"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.29M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b68f9050e8c144338947498b756def14"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/239 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c856aa769d634ec4a6b7c4acdab2055a"}},"metadata":{}}]},{"cell_type":"code","source":"%%time\ndls = dblock.dataloaders(train_ds, bs=bs, val_bs=val_bs)","metadata":{"execution":{"iopub.status.busy":"2022-06-01T20:30:54.016950Z","iopub.execute_input":"2022-06-01T20:30:54.019570Z","iopub.status.idle":"2022-06-01T20:31:08.256645Z","shell.execute_reply.started":"2022-06-01T20:30:54.019529Z","shell.execute_reply":"2022-06-01T20:31:08.255761Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"CPU times: user 8.17 s, sys: 1.76 s, total: 9.93 s\nWall time: 14.2 s\n","output_type":"stream"}]},{"cell_type":"code","source":"dls.show_batch(max_n=5)","metadata":{"execution":{"iopub.status.busy":"2022-06-01T20:31:08.260928Z","iopub.execute_input":"2022-06-01T20:31:08.263010Z","iopub.status.idle":"2022-06-01T20:31:08.360939Z","shell.execute_reply.started":"2022-06-01T20:31:08.262970Z","shell.execute_reply":"2022-06-01T20:31:08.360012Z"},"trusted":true},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>text_</th>\n      <th>category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Amrozi accused his brother, whom he called \" the witness \", of deliberately distorting his evidence.</td>\n      <td>Referring to him as only \" the witness \", Amrozi accused his brother of deliberately distorting his evidence.</td>\n      <td>equivalent</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Most of the alleged spammers engaged in fraudulent or deceptive practices, said Brad Smith, Microsoft's senior VP and general counsel.</td>\n      <td>\" Spam knows no borders, \" said Brad Smith, Microsoft's senior vice-president and general counsel.</td>\n      <td>not_equivalent</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Yesterday, Taiwan reported 35 new infections, bringing the total number of cases to 418.</td>\n      <td>The island reported another 35 probable cases yesterday, taking its total to 418.</td>\n      <td>equivalent</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>A month ago, the Commerce Department estimated that GDP had grown at a 7.2 percent rate in the third quarter.</td>\n      <td>A month ago, the Commerce Department said GDP grew at a 7.2 percent rate.</td>\n      <td>equivalent</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Gillespie sent a letter to CBS President Leslie Moonves asking for a historical review or a disclaimer.</td>\n      <td>Republican National Committee Chairman Ed Gillespie issued a letter Friday to CBS Television President Leslie Moonves.</td>\n      <td>not_equivalent</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}}]},{"cell_type":"code","source":"import wandb\n\nWANDB_NAME = f'{ds_name}-{task}-{model_name}'\nGROUP = f'{ds_name}-{task}-{model_name}-{lr:.0e}'\nNOTES = f'finetuning {model_name} with RAdam lr={lr:.0e}'\nCONFIG = {}\nTAGS =[model_name, ds_name, 'radam']","metadata":{"execution":{"iopub.status.busy":"2022-06-01T20:31:08.364892Z","iopub.execute_input":"2022-06-01T20:31:08.367006Z","iopub.status.idle":"2022-06-01T20:31:08.374540Z","shell.execute_reply.started":"2022-06-01T20:31:08.366968Z","shell.execute_reply":"2022-06-01T20:31:08.373675Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"wandb.init(reinit=True, project=\"fasthugs\", entity=\"fastai_community\",\n           name=WANDB_NAME, group=GROUP, notes=NOTES, tags=TAGS, config=CONFIG);","metadata":{"execution":{"iopub.status.busy":"2022-06-01T20:31:08.379956Z","iopub.execute_input":"2022-06-01T20:31:08.382301Z","iopub.status.idle":"2022-06-01T20:31:24.103184Z","shell.execute_reply.started":"2022-06-01T20:31:08.382265Z","shell.execute_reply":"2022-06-01T20:31:24.102400Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.12.17 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.12.16"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20220601_203117-2p8pauw7</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href=\"https://wandb.ai/fastai_community/fasthugs/runs/2p8pauw7\" target=\"_blank\">glue-mrpc-AnonymousSub/rule_based_roberta_hier_triplet_epochs_1_shard_1</a></strong> to <a href=\"https://wandb.ai/fastai_community/fasthugs\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"},"metadata":{}}]},{"cell_type":"code","source":"model = AutoModelForSequenceClassification.from_pretrained(model_name)\nmetrics = glue_metrics[task]\nlearn = TransLearner(dls, model, metrics=metrics).to_fp16()","metadata":{"execution":{"iopub.status.busy":"2022-06-01T20:31:24.104374Z","iopub.execute_input":"2022-06-01T20:31:24.108918Z","iopub.status.idle":"2022-06-01T20:31:47.265063Z","shell.execute_reply.started":"2022-06-01T20:31:24.108873Z","shell.execute_reply":"2022-06-01T20:31:47.263118Z"},"trusted":true},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/723 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f81db30da8e44dba21e34e9085b8a7e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/476M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f7cebd43aa8482bb1c4cba961d934d8"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at AnonymousSub/rule_based_roberta_hier_triplet_epochs_1_shard_1 were not used when initializing RobertaForSequenceClassification: ['pooler.dense.weight', 'pooler.dense.bias']\n- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of RobertaForSequenceClassification were not initialized from the model checkpoint at AnonymousSub/rule_based_roberta_hier_triplet_epochs_1_shard_1 and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"cbs = [WandbCallback(log_preds=False, log_model=False), SaveModelCallback(monitor=metrics[0].name)]\nlearn.fit_one_cycle(10, lr, cbs=cbs)","metadata":{"execution":{"iopub.status.busy":"2022-06-01T20:31:47.280240Z","iopub.execute_input":"2022-06-01T20:31:47.289748Z","iopub.status.idle":"2022-06-01T20:38:01.276132Z","shell.execute_reply.started":"2022-06-01T20:31:47.289710Z","shell.execute_reply":"2022-06-01T20:38:01.274468Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Could not gather input dimensions\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>f1_score</th>\n      <th>accuracy</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.607585</td>\n      <td>0.562150</td>\n      <td>0.812227</td>\n      <td>0.683824</td>\n      <td>00:37</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>0.480501</td>\n      <td>0.360215</td>\n      <td>0.892794</td>\n      <td>0.850490</td>\n      <td>00:36</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.342549</td>\n      <td>0.294814</td>\n      <td>0.898917</td>\n      <td>0.862745</td>\n      <td>00:36</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.224088</td>\n      <td>0.312952</td>\n      <td>0.902622</td>\n      <td>0.872549</td>\n      <td>00:35</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.135990</td>\n      <td>0.357275</td>\n      <td>0.926746</td>\n      <td>0.894608</td>\n      <td>00:36</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.063998</td>\n      <td>0.379349</td>\n      <td>0.930973</td>\n      <td>0.904412</td>\n      <td>00:35</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.032440</td>\n      <td>0.415722</td>\n      <td>0.925000</td>\n      <td>0.897059</td>\n      <td>00:35</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.023815</td>\n      <td>0.461870</td>\n      <td>0.927944</td>\n      <td>0.899510</td>\n      <td>00:35</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.013648</td>\n      <td>0.504336</td>\n      <td>0.929078</td>\n      <td>0.901961</td>\n      <td>00:37</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.012766</td>\n      <td>0.506984</td>\n      <td>0.923351</td>\n      <td>0.894608</td>\n      <td>00:36</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nBetter model found at epoch 0 with f1_score value: 0.8122270742358079.\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nBetter model found at epoch 1 with f1_score value: 0.8927943760984183.\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nBetter model found at epoch 2 with f1_score value: 0.8989169675090252.\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nBetter model found at epoch 3 with f1_score value: 0.902621722846442.\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nBetter model found at epoch 4 with f1_score value: 0.9267461669505962.\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nBetter model found at epoch 5 with f1_score value: 0.9309734513274337.\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"}]},{"cell_type":"code","source":"learn.show_results()","metadata":{"execution":{"iopub.status.busy":"2022-06-01T20:38:01.280113Z","iopub.execute_input":"2022-06-01T20:38:01.280722Z","iopub.status.idle":"2022-06-01T20:38:01.654965Z","shell.execute_reply.started":"2022-06-01T20:38:01.280678Z","shell.execute_reply":"2022-06-01T20:38:01.654060Z"},"trusted":true},"execution_count":22,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>text_</th>\n      <th>category</th>\n      <th>category_</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>He said the foodservice pie business doesn 't fit the company's long-term growth strategy.</td>\n      <td>\" The foodservice pie business does not fit our long-term growth strategy.</td>\n      <td>equivalent</td>\n      <td>equivalent</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>About 1,500 police will be deployed for the visit.</td>\n      <td>Around 1,500 police are to be deployed at Niigata for the ferry's visit.</td>\n      <td>equivalent</td>\n      <td>equivalent</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Magnarelli said Racicot hated the Iraqi regime and looked forward to using his long years of training in the war.</td>\n      <td>His wife said he was \" 100 percent behind George Bush \" and looked forward to using his years of training in the war.</td>\n      <td>not_equivalent</td>\n      <td>not_equivalent</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Federal Agriculture Minister Warren Truss said the Government still did not know the real reason the sheep were rejected at the Saudi port of Jeddah on August 21.</td>\n      <td>He said the Government still did not know the real reason the original Saudi buyer pulled out on August 21.</td>\n      <td>equivalent</td>\n      <td>equivalent</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>BREAST cancer cases in the UK have hit an all-time high with more than 40,000 women diagnosed with the disease each year, Cancer Re-search UK revealed yesterday.</td>\n      <td>Cases of breast cancer in Britain have reached a record high, with the number of women diagnosed with the disease passing the 40,000 mark for the first time.</td>\n      <td>equivalent</td>\n      <td>equivalent</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>With these assets, Funny Cide has a solid chance to become the first Triple Crown winner since Affirmed in 1978.</td>\n      <td>Funny Cide is looking to become horse racing's first Triple Crown winner in a generation.</td>\n      <td>not_equivalent</td>\n      <td>not_equivalent</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Gilead had earnings of $ 73.1 million, or 33 cents a share, compared with $ 20.8 million, or 10 cents, in the year-ago quarter.</td>\n      <td>Quarterly profit climbed to $ 73.1 million, or 33 cents a share, from $ 20.8 million, or 10 cents, a year earlier, the company said.</td>\n      <td>equivalent</td>\n      <td>equivalent</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Mr. Clinton's national security adviser, Sandy Berger, said that the White House wasn 't informed of the FBI activities.</td>\n      <td>Clinton ’ s national security adviser, Sandy Berger, said in an interview that the White House was not informed of the FBI activities.</td>\n      <td>equivalent</td>\n      <td>equivalent</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>He said : \" For the first time there is an easy and affordable way of making this treasure trove of BBC content available to all. \"</td>\n      <td>\" For the first time, there is an easy and affordable way of making this treasure trove of BBC content available to all, \" Dyke said.</td>\n      <td>equivalent</td>\n      <td>equivalent</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
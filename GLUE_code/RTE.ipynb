{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install fasthugs","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2022-06-02T03:30:25.125601Z","iopub.execute_input":"2022-06-02T03:30:25.126052Z","iopub.status.idle":"2022-06-02T03:30:44.210318Z","shell.execute_reply.started":"2022-06-02T03:30:25.125966Z","shell.execute_reply":"2022-06-02T03:30:44.209127Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting fasthugs\n  Downloading fasthugs-0.0.1-py3-none-any.whl (15 kB)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from fasthugs) (21.3)\nRequirement already satisfied: torch>=1.7.1 in /opt/conda/lib/python3.7/site-packages (from fasthugs) (1.11.0)\nRequirement already satisfied: fastcore in /opt/conda/lib/python3.7/site-packages (from fasthugs) (1.4.3)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (from fasthugs) (4.18.0)\nRequirement already satisfied: fastai>=2.2.2 in /opt/conda/lib/python3.7/site-packages (from fasthugs) (2.6.3)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.7/site-packages (from fasthugs) (2.1.0)\nRequirement already satisfied: pip in /opt/conda/lib/python3.7/site-packages (from fasthugs) (22.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from fastai>=2.2.2->fasthugs) (2.27.1)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from fastai>=2.2.2->fasthugs) (1.3.5)\nRequirement already satisfied: spacy<4 in /opt/conda/lib/python3.7/site-packages (from fastai>=2.2.2->fasthugs) (3.2.4)\nRequirement already satisfied: fastprogress>=0.2.4 in /opt/conda/lib/python3.7/site-packages (from fastai>=2.2.2->fasthugs) (1.0.2)\nRequirement already satisfied: torchvision>=0.8.2 in /opt/conda/lib/python3.7/site-packages (from fastai>=2.2.2->fasthugs) (0.12.0)\nRequirement already satisfied: pillow>6.0.0 in /opt/conda/lib/python3.7/site-packages (from fastai>=2.2.2->fasthugs) (9.1.0)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from fastai>=2.2.2->fasthugs) (1.0.2)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from fastai>=2.2.2->fasthugs) (3.5.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from fastai>=2.2.2->fasthugs) (1.7.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from fastai>=2.2.2->fasthugs) (6.0)\nRequirement already satisfied: fastdownload<2,>=0.0.5 in /opt/conda/lib/python3.7/site-packages (from fastai>=2.2.2->fasthugs) (0.0.6)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.7.1->fasthugs) (4.2.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from datasets->fasthugs) (1.21.6)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.7/site-packages (from datasets->fasthugs) (3.0.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.7/site-packages (from datasets->fasthugs) (4.64.0)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.7/site-packages (from datasets->fasthugs) (2022.5.0)\nRequirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from datasets->fasthugs) (0.5.1)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.7/site-packages (from datasets->fasthugs) (5.0.0)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.7/site-packages (from datasets->fasthugs) (0.70.13)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from datasets->fasthugs) (4.11.4)\nRequirement already satisfied: dill in /opt/conda/lib/python3.7/site-packages (from datasets->fasthugs) (0.3.5.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from datasets->fasthugs) (3.8.1)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.7/site-packages (from datasets->fasthugs) (0.18.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->fasthugs) (3.0.9)\nRequirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers->fasthugs) (0.0.53)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers->fasthugs) (2021.11.10)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers->fasthugs) (3.6.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers->fasthugs) (0.12.1)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->fastai>=2.2.2->fasthugs) (2022.5.18.1)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->fastai>=2.2.2->fasthugs) (1.26.9)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests->fastai>=2.2.2->fasthugs) (2.0.12)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->fastai>=2.2.2->fasthugs) (3.3)\nRequirement already satisfied: srsly<3.0.0,>=2.4.1 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai>=2.2.2->fasthugs) (2.4.3)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai>=2.2.2->fasthugs) (2.0.6)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai>=2.2.2->fasthugs) (3.1.2)\nRequirement already satisfied: typer<0.5.0,>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai>=2.2.2->fasthugs) (0.4.1)\nRequirement already satisfied: thinc<8.1.0,>=8.0.12 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai>=2.2.2->fasthugs) (8.0.16)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai>=2.2.2->fasthugs) (3.0.6)\nCollecting typing-extensions\n  Downloading typing_extensions-3.10.0.2-py3-none-any.whl (26 kB)\nRequirement already satisfied: click<8.1.0 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai>=2.2.2->fasthugs) (8.0.4)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai>=2.2.2->fasthugs) (1.8.2)\nRequirement already satisfied: wasabi<1.1.0,>=0.8.1 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai>=2.2.2->fasthugs) (0.9.1)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai>=2.2.2->fasthugs) (1.0.2)\nRequirement already satisfied: blis<0.8.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai>=2.2.2->fasthugs) (0.7.7)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai>=2.2.2->fasthugs) (3.3.0)\nRequirement already satisfied: pathy>=0.3.5 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai>=2.2.2->fasthugs) (0.6.1)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai>=2.2.2->fasthugs) (3.0.9)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai>=2.2.2->fasthugs) (1.0.7)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai>=2.2.2->fasthugs) (2.0.7)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai>=2.2.2->fasthugs) (59.8.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets->fasthugs) (1.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets->fasthugs) (1.3.0)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets->fasthugs) (1.7.2)\nRequirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets->fasthugs) (0.13.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets->fasthugs) (21.4.0)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets->fasthugs) (4.0.2)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets->fasthugs) (6.0.2)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->datasets->fasthugs) (3.8.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->fastai>=2.2.2->fasthugs) (0.11.0)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib->fastai>=2.2.2->fasthugs) (2.8.2)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->fastai>=2.2.2->fasthugs) (4.33.3)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->fastai>=2.2.2->fasthugs) (1.4.2)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->fastai>=2.2.2->fasthugs) (2022.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers->fasthugs) (1.16.0)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers->fasthugs) (1.1.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->fastai>=2.2.2->fasthugs) (3.1.0)\nRequirement already satisfied: smart-open<6.0.0,>=5.0.0 in /opt/conda/lib/python3.7/site-packages (from pathy>=0.3.5->spacy<4->fastai>=2.2.2->fasthugs) (5.2.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.7/site-packages (from jinja2->spacy<4->fastai>=2.2.2->fasthugs) (2.0.1)\nInstalling collected packages: typing-extensions, fasthugs\n  Attempting uninstall: typing-extensions\n    Found existing installation: typing_extensions 4.2.0\n    Uninstalling typing_extensions-4.2.0:\n      Successfully uninstalled typing_extensions-4.2.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-io 0.21.0 requires tensorflow-io-gcs-filesystem==0.21.0, which is not installed.\ntensorflow 2.6.4 requires absl-py~=0.10, but you have absl-py 1.0.0 which is incompatible.\ntensorflow 2.6.4 requires numpy~=1.19.2, but you have numpy 1.21.6 which is incompatible.\ntensorflow 2.6.4 requires six~=1.15.0, but you have six 1.16.0 which is incompatible.\ntensorflow 2.6.4 requires wrapt~=1.12.1, but you have wrapt 1.14.1 which is incompatible.\ntensorflow-transform 1.8.0 requires tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<2.9,>=1.15.5, but you have tensorflow 2.6.4 which is incompatible.\ntensorflow-serving-api 2.8.0 requires tensorflow<3,>=2.8.0, but you have tensorflow 2.6.4 which is incompatible.\nrich 12.4.4 requires typing-extensions<5.0,>=4.0.0; python_version < \"3.9\", but you have typing-extensions 3.10.0.2 which is incompatible.\npytorch-lightning 1.6.3 requires typing-extensions>=4.0.0, but you have typing-extensions 3.10.0.2 which is incompatible.\npytools 2022.1.9 requires typing-extensions>=4.0; python_version < \"3.11\", but you have typing-extensions 3.10.0.2 which is incompatible.\nflax 0.5.0 requires typing-extensions>=4.1.1, but you have typing-extensions 3.10.0.2 which is incompatible.\nflake8 4.0.1 requires importlib-metadata<4.3; python_version < \"3.8\", but you have importlib-metadata 4.11.4 which is incompatible.\napache-beam 2.38.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.5.1 which is incompatible.\napache-beam 2.38.0 requires httplib2<0.20.0,>=0.8, but you have httplib2 0.20.4 which is incompatible.\naioitertools 0.10.0 requires typing_extensions>=4.0; python_version < \"3.10\", but you have typing-extensions 3.10.0.2 which is incompatible.\naiobotocore 2.3.2 requires botocore<1.24.22,>=1.24.21, but you have botocore 1.26.7 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed fasthugs-0.0.1 typing-extensions-3.10.0.2\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification\nfrom fastai.text.all import *\nfrom fastai.callback.wandb import *\n\nfrom fasthugs.learner import TransLearner\nfrom fasthugs.data import TransformersTextBlock, TextGetter, get_splits, PreprocCategoryBlock\n\nfrom datasets import load_dataset, concatenate_datasets\n\nimport random \nimport numpy as np\nimport torch\n\ndef random_seed(seed_value): \n    np.random.seed(seed_value) \n    torch.manual_seed(seed_value)\n    random.seed(seed_value) \n\n\nrandom_seed(42)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T03:30:57.246126Z","iopub.execute_input":"2022-06-02T03:30:57.246707Z","iopub.status.idle":"2022-06-02T03:31:12.673529Z","shell.execute_reply.started":"2022-06-02T03:30:57.246661Z","shell.execute_reply":"2022-06-02T03:31:12.668854Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"ds_name = 'glue'\nmodel_name = \"AnonymousSub/rule_based_roberta_hier_triplet_epochs_1_shard_1\"\n\nmax_len = 512\nbs = 32\nval_bs = bs*2\n\nlr = 3e-5","metadata":{"execution":{"iopub.status.busy":"2022-06-02T03:31:12.675442Z","iopub.execute_input":"2022-06-02T03:31:12.678083Z","iopub.status.idle":"2022-06-02T03:31:12.703062Z","shell.execute_reply.started":"2022-06-02T03:31:12.678016Z","shell.execute_reply":"2022-06-02T03:31:12.687487Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"GLUE_TASKS = [\"cola\", \"mnli\", \"mnli-mm\", \"mrpc\", \"qnli\", \"qqp\", \"rte\", \"sst2\", \"stsb\", \"wnli\"]\ndef validate_task():\n    assert task in GLUE_TASKS","metadata":{"execution":{"iopub.status.busy":"2022-06-02T03:31:12.704688Z","iopub.execute_input":"2022-06-02T03:31:12.705277Z","iopub.status.idle":"2022-06-02T03:31:12.715674Z","shell.execute_reply.started":"2022-06-02T03:31:12.705235Z","shell.execute_reply":"2022-06-02T03:31:12.713572Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from fastai.metrics import MatthewsCorrCoef, F1Score, PearsonCorrCoef, SpearmanCorrCoef","metadata":{"execution":{"iopub.status.busy":"2022-06-02T03:31:12.718006Z","iopub.execute_input":"2022-06-02T03:31:12.718593Z","iopub.status.idle":"2022-06-02T03:31:12.730562Z","shell.execute_reply.started":"2022-06-02T03:31:12.718555Z","shell.execute_reply":"2022-06-02T03:31:12.728713Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"glue_metrics = {\n    'cola':[MatthewsCorrCoef()],\n    'sst2':[accuracy],\n    'mrpc':[F1Score(), accuracy],\n    'stsb':[PearsonCorrCoef(), SpearmanCorrCoef()],\n    'qqp' :[F1Score(), accuracy],\n    'mnli':[accuracy],\n    'qnli':[accuracy],\n    'rte' :[accuracy],\n    'wnli':[accuracy],\n}","metadata":{"execution":{"iopub.status.busy":"2022-06-02T03:31:12.732041Z","iopub.execute_input":"2022-06-02T03:31:12.732422Z","iopub.status.idle":"2022-06-02T03:31:12.745567Z","shell.execute_reply.started":"2022-06-02T03:31:12.732388Z","shell.execute_reply":"2022-06-02T03:31:12.742797Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"task = 'rte'\nvalidate_task()","metadata":{"execution":{"iopub.status.busy":"2022-06-02T03:31:12.747076Z","iopub.execute_input":"2022-06-02T03:31:12.747625Z","iopub.status.idle":"2022-06-02T03:31:12.756611Z","shell.execute_reply.started":"2022-06-02T03:31:12.747586Z","shell.execute_reply":"2022-06-02T03:31:12.755555Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"ds = load_dataset(ds_name, task)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T03:31:12.757765Z","iopub.execute_input":"2022-06-02T03:31:12.758423Z","iopub.status.idle":"2022-06-02T03:31:16.150939Z","shell.execute_reply.started":"2022-06-02T03:31:12.758371Z","shell.execute_reply":"2022-06-02T03:31:16.150151Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/7.78k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"78917053f6bd4ea7aba8155605340736"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading metadata:   0%|          | 0.00/4.47k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d38d5e42f974c5da27879695b890481"}},"metadata":{}},{"name":"stdout","text":"Downloading and preparing dataset glue/rte (download: 680.81 KiB, generated: 1.83 MiB, post-processed: Unknown size, total: 2.49 MiB) to /root/.cache/huggingface/datasets/glue/rte/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/697k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"54a67ef2994e4f9c93ebee5fc88046a5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/2490 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/277 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/3000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset glue downloaded and prepared to /root/.cache/huggingface/datasets/glue/rte/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"10368c01c8194e5eb526559e62bdf58c"}},"metadata":{}}]},{"cell_type":"code","source":"ds.keys()","metadata":{"execution":{"iopub.status.busy":"2022-06-02T03:31:16.152218Z","iopub.execute_input":"2022-06-02T03:31:16.152722Z","iopub.status.idle":"2022-06-02T03:31:16.164067Z","shell.execute_reply.started":"2022-06-02T03:31:16.152685Z","shell.execute_reply":"2022-06-02T03:31:16.162998Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"dict_keys(['train', 'validation', 'test'])"},"metadata":{}}]},{"cell_type":"code","source":"len(ds['train']), len(ds['validation'])","metadata":{"execution":{"iopub.status.busy":"2022-06-02T03:31:16.165676Z","iopub.execute_input":"2022-06-02T03:31:16.166335Z","iopub.status.idle":"2022-06-02T03:31:16.176374Z","shell.execute_reply.started":"2022-06-02T03:31:16.166293Z","shell.execute_reply":"2022-06-02T03:31:16.175430Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"(2490, 277)"},"metadata":{}}]},{"cell_type":"code","source":"train_idx, valid_idx = get_splits(ds)\nvalid_idx","metadata":{"execution":{"iopub.status.busy":"2022-06-02T03:31:16.180230Z","iopub.execute_input":"2022-06-02T03:31:16.180888Z","iopub.status.idle":"2022-06-02T03:31:16.188001Z","shell.execute_reply.started":"2022-06-02T03:31:16.180845Z","shell.execute_reply":"2022-06-02T03:31:16.187140Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"(#277) [2490,2491,2492,2493,2494,2495,2496,2497,2498,2499...]"},"metadata":{}}]},{"cell_type":"code","source":"train_ds = concatenate_datasets([ds['train'], ds['validation']])","metadata":{"execution":{"iopub.status.busy":"2022-06-02T03:31:16.190958Z","iopub.execute_input":"2022-06-02T03:31:16.191627Z","iopub.status.idle":"2022-06-02T03:31:16.208552Z","shell.execute_reply.started":"2022-06-02T03:31:16.191587Z","shell.execute_reply":"2022-06-02T03:31:16.207802Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"train_ds[0]","metadata":{"execution":{"iopub.status.busy":"2022-06-02T03:31:16.209785Z","iopub.execute_input":"2022-06-02T03:31:16.210263Z","iopub.status.idle":"2022-06-02T03:31:16.221683Z","shell.execute_reply.started":"2022-06-02T03:31:16.210228Z","shell.execute_reply":"2022-06-02T03:31:16.220790Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"{'sentence1': 'No Weapons of Mass Destruction Found in Iraq Yet.',\n 'sentence2': 'Weapons of Mass Destruction Found in Iraq.',\n 'label': 1,\n 'idx': 0}"},"metadata":{}}]},{"cell_type":"code","source":"vocab = train_ds.features['label'].names\ndblock = DataBlock(blocks = [TransformersTextBlock(pretrained_model_name=model_name), PreprocCategoryBlock(vocab)],\n                   get_x=TextGetter('sentence1', 'sentence2'),\n                   get_y=ItemGetter('label'),\n                   splitter=IndexSplitter(valid_idx))","metadata":{"execution":{"iopub.status.busy":"2022-06-02T03:31:16.223170Z","iopub.execute_input":"2022-06-02T03:31:16.224147Z","iopub.status.idle":"2022-06-02T03:31:22.311390Z","shell.execute_reply.started":"2022-06-02T03:31:16.223725Z","shell.execute_reply":"2022-06-02T03:31:22.310543Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/384 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"04e71bd6ba4b49efbc16615ee7755696"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/780k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"92db7b3befdf46fd893d868da494d37f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e69b4801678549e28599cd67c0bc5d04"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.29M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0047389e297a44018e044466bfb4e233"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/239 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a875bc8e9efa48b0a929a40b79ac8bba"}},"metadata":{}}]},{"cell_type":"code","source":"%%time\ndls = dblock.dataloaders(train_ds, bs=bs, val_bs=val_bs)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T03:31:22.316456Z","iopub.execute_input":"2022-06-02T03:31:22.318633Z","iopub.status.idle":"2022-06-02T03:31:34.610294Z","shell.execute_reply.started":"2022-06-02T03:31:22.318594Z","shell.execute_reply":"2022-06-02T03:31:34.609391Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"CPU times: user 6.67 s, sys: 1.79 s, total: 8.46 s\nWall time: 12.3 s\n","output_type":"stream"}]},{"cell_type":"code","source":"dls.show_batch(max_n=5)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T03:31:34.614290Z","iopub.execute_input":"2022-06-02T03:31:34.616384Z","iopub.status.idle":"2022-06-02T03:31:34.748141Z","shell.execute_reply.started":"2022-06-02T03:31:34.616346Z","shell.execute_reply":"2022-06-02T03:31:34.747345Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>text_</th>\n      <th>category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>No Weapons of Mass Destruction Found in Iraq Yet.</td>\n      <td>Weapons of Mass Destruction Found in Iraq.</td>\n      <td>not_entailment</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>India's steelmaker Tata Steel, of the Tata Group, buys Anglo-Dutch steel giant Corus Group for £6.7 billion ($12 billion), making it the world's fifth largest steel manufacturer. 70-year-old Tata group Chairman Ratan Tata, from one of India's best-known business families, won the race against Benjamin Steinbruch, 52, a famous Brazilian executive who is the chief and main owner of Companhia Siderurgica Nacional (CSN). Tata paid investors 608 pence a share, whereas the Brazilians final offer in an auction by the U.K.'s Takeover Panel was 603 pence. The deal triples Tata Steel's capacity to almost 28 million tons a year. Tata: \"This is the first step in showing that Indian industry can step outside its shores into an international market place as a global player.\" Corus, which was created from the merger of British Steel and Hoogovens, currently employs 47,300 people worldwide. Last year the company was the ninth-largest steel maker</td>\n      <td>Tata group was founded 70 years ago.</td>\n      <td>not_entailment</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Late Tuesday, authorities in the U.S. state of Texas carried out the execution of José Medellín, a Mexican national convicted of raping and murdering two teenage girls in 1993. The execution was carried out despite being at the center of an international legal dispute with objections from the International Court of Justice (ICJ) and UN Secretary-General Ban Ki-moon. José Ernesto Medellín, 33, was born in Mexico but moved to the U.S. as a child. He was sentenced to death for the 1993 rape and murder of two girls aged 14 and 16 in Houston, Texas. On Tuesday at 9:57 p.m. CDT, he was given a lethal injection at the Huntsville Unit in Huntsville, according to the Texas Department of Criminal Justice.</td>\n      <td>José Medellín was executed in Huntsville prison.</td>\n      <td>entailment</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Prosecutors were still expected to unseal an 11-count manslaughter indictment against the ferry's captain, Michael Gansas.</td>\n      <td>Gansas' attorneys have said that rule was not communicated to ferry staff.</td>\n      <td>not_entailment</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>According to tradition, they founded Tenochtitlan ( \"Place of the High Priest Tenoch\" ) after much wandering when they saw on an island in Lake Texcoco the sign that their god Huitzilopochtli had indicated -- an eagle perched on a cactus, eating a serpent.</td>\n      <td>They saw an eagle perched on a cactus eating a serpent.</td>\n      <td>entailment</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}}]},{"cell_type":"code","source":"import wandb\n\nWANDB_NAME = f'{ds_name}-{task}-{model_name}'\nGROUP = f'{ds_name}-{task}-{model_name}-{lr:.0e}'\nNOTES = f'finetuning {model_name} with RAdam lr={lr:.0e}'\nCONFIG = {}\nTAGS =[model_name, ds_name, 'radam']","metadata":{"execution":{"iopub.status.busy":"2022-06-02T03:31:34.752200Z","iopub.execute_input":"2022-06-02T03:31:34.754343Z","iopub.status.idle":"2022-06-02T03:31:34.761971Z","shell.execute_reply.started":"2022-06-02T03:31:34.754304Z","shell.execute_reply":"2022-06-02T03:31:34.761004Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"#wandb.init(reinit=True, project=\"fasthugs\", entity=\"fastai_community\",\n#           name=WANDB_NAME, group=GROUP, notes=NOTES, tags=TAGS, config=CONFIG);","metadata":{"execution":{"iopub.status.busy":"2022-06-02T03:31:34.767971Z","iopub.execute_input":"2022-06-02T03:31:34.771203Z","iopub.status.idle":"2022-06-02T03:31:34.777066Z","shell.execute_reply.started":"2022-06-02T03:31:34.771162Z","shell.execute_reply":"2022-06-02T03:31:34.776015Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"model = AutoModelForSequenceClassification.from_pretrained(model_name)\nmetrics = glue_metrics[task]\nlearn = TransLearner(dls, model, metrics=metrics).to_fp16()","metadata":{"execution":{"iopub.status.busy":"2022-06-02T03:31:34.782318Z","iopub.execute_input":"2022-06-02T03:31:34.784028Z","iopub.status.idle":"2022-06-02T03:32:05.142144Z","shell.execute_reply.started":"2022-06-02T03:31:34.783974Z","shell.execute_reply":"2022-06-02T03:32:05.141388Z"},"trusted":true},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/723 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c614d3760cf04d869fe1df63273d5d7c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/476M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"52858f9ac00e464291a75f12df722c48"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at AnonymousSub/rule_based_roberta_hier_triplet_epochs_1_shard_1 were not used when initializing RobertaForSequenceClassification: ['pooler.dense.bias', 'pooler.dense.weight']\n- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of RobertaForSequenceClassification were not initialized from the model checkpoint at AnonymousSub/rule_based_roberta_hier_triplet_epochs_1_shard_1 and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"cbs = []\nlearn.fit_one_cycle(10, lr, cbs=cbs)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T03:32:05.145952Z","iopub.execute_input":"2022-06-02T03:32:05.148074Z","iopub.status.idle":"2022-06-02T03:39:59.762285Z","shell.execute_reply.started":"2022-06-02T03:32:05.148033Z","shell.execute_reply":"2022-06-02T03:39:59.761248Z"},"trusted":true},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>accuracy</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.696475</td>\n      <td>0.692079</td>\n      <td>0.472924</td>\n      <td>00:48</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>0.690902</td>\n      <td>0.660299</td>\n      <td>0.675090</td>\n      <td>00:47</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.633742</td>\n      <td>0.626834</td>\n      <td>0.649819</td>\n      <td>00:46</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.521423</td>\n      <td>0.481939</td>\n      <td>0.740072</td>\n      <td>00:47</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.396643</td>\n      <td>0.503545</td>\n      <td>0.779783</td>\n      <td>00:47</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.231653</td>\n      <td>0.730623</td>\n      <td>0.765343</td>\n      <td>00:47</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.140531</td>\n      <td>0.670045</td>\n      <td>0.787004</td>\n      <td>00:46</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.087451</td>\n      <td>0.830842</td>\n      <td>0.790614</td>\n      <td>00:47</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.054648</td>\n      <td>0.769149</td>\n      <td>0.790614</td>\n      <td>00:47</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.045804</td>\n      <td>0.798510</td>\n      <td>0.790614</td>\n      <td>00:47</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"}]},{"cell_type":"code","source":"learn.show_results()","metadata":{"execution":{"iopub.status.busy":"2022-06-02T03:39:59.766535Z","iopub.execute_input":"2022-06-02T03:39:59.769021Z","iopub.status.idle":"2022-06-02T03:40:00.444197Z","shell.execute_reply.started":"2022-06-02T03:39:59.768976Z","shell.execute_reply":"2022-06-02T03:40:00.443164Z"},"trusted":true},"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>text_</th>\n      <th>category</th>\n      <th>category_</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Dana Reeve, the widow of the actor Christopher Reeve, has died of lung cancer at age 44, according to the Christopher Reeve Foundation.</td>\n      <td>Christopher Reeve had an accident.</td>\n      <td>not_entailment</td>\n      <td>not_entailment</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Two brothers who operated a North Hollywood plating company that dumped thousands of gallons of cyanide-laced waste water into the Los Angeles sewer system pleaded guilty Thursday and must serve jail time for recklessly handling and storing hazardous materials.</td>\n      <td>A California company was charged with reckless storage of chemicals.</td>\n      <td>entailment</td>\n      <td>entailment</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>As spacecraft commander for Apollo XI, the first manned lunar landing mission, Armstrong was the first man to walk on the Moon. \"That's one small step for a man, one giant leap for mankind.\" With these historic words, man's dream of the ages was fulfilled.</td>\n      <td>Neil Armstrong was the first man who landed on the Moon.</td>\n      <td>entailment</td>\n      <td>entailment</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>The job gains mean that  President Bush can celebrate - albeit by a very fine margin - a net growth in jobs in the US economy in his first term in office.</td>\n      <td>More jobs were created during President Bush's first term.</td>\n      <td>entailment</td>\n      <td>entailment</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>California voters recall Gray Davis and elect Arnold Schwarzenegger as their governor.</td>\n      <td>California voters dumped Gov. Gray Davis and replaced him with Arnold Schwarzenegger.</td>\n      <td>entailment</td>\n      <td>not_entailment</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>As a result of these weaknesses, computer systems and the operations that rely on the systems were highly vulnerable to tampering, disruption, and misuse from both internal and external sources.</td>\n      <td>Non-authorized personnel illegally entered into computer networks.</td>\n      <td>not_entailment</td>\n      <td>not_entailment</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Swansea striker Lee Trundle has negotiated a lucrative image-rights deal with the League One club.</td>\n      <td>Lee Trundle is in business with the League One club.</td>\n      <td>entailment</td>\n      <td>entailment</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Italian film-maker, Fellini was awarded an honorary Oscar for lifetime achievement. He died on October 31, 1993.</td>\n      <td>An Italian director is awarded an honorary Oscar.</td>\n      <td>entailment</td>\n      <td>entailment</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>South America - The President of Colombia Alvaro Uribe is scheduled to meet the President of Venezuela Hugo Chávez Thursday. Apparently the crisis between Venezuela and Colombia is almost solved. The crisis began with the imprisonment of the alleged FARC member Rodrigo Granda by Colombian forces on December 13, 2004. Venezuela accused Colombian of invading Venezuelan territory. Colombia accused Venezuela of harboring FARC terrorists. The President of Cuba, Fidel Castro, intervened in the crisis and talked to Chavez and Uribe.</td>\n      <td>Alvaro Uribe is the current President of Colombia.</td>\n      <td>entailment</td>\n      <td>entailment</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}